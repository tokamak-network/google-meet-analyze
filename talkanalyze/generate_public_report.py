#!/usr/bin/env python3
"""
ëŒ€ì¤‘ìš© ë°ì¼ë¦¬ ë¦¬í¬íŠ¸ ìƒì„±ê¸° (íˆ¬ìì, íŒŒíŠ¸ë„ˆì‚¬, ì»¤ë®¤ë‹ˆí‹°ìš©)
Usage: python generate_public_report.py --date 2026-02-03

íŠ¹ì§•:
- ê¸°ìˆ  ìš©ì–´ ìµœì†Œí™”
- ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ê³¼ ë° ë§ˆì¼ìŠ¤í†¤ ì¤‘ì‹¬
- ì „ëµì  ë°©í–¥ì„± ê°•ì¡°
- ë‚´ë¶€ ì•¡ì…˜ì•„ì´í…œ ì œì™¸
- PR ì¹œí™”ì  í†¤ì•¤ë§¤ë„ˆ
"""

import csv
import sys
import re
import argparse
from collections import defaultdict
from pathlib import Path
from datetime import date

csv.field_size_limit(sys.maxsize)

# ============================================================================
# ì„¤ì •
# ============================================================================

NAME_MAP = {
    'YEONGJU BAK': 'Zena',
    'Jason Hwang': 'Jason',
    'Harvey Jo': 'Harvey',
    'Aryan Soni': 'Aryan',
    'Suhyeon Lee': 'Suhyeon',
    'Sahil Wasnik': 'Sahil',
    'Singh Shailendra': 'Singh',
    'Praveen Surendran': 'Praveen',
    'Manish Kumar': 'Manish',
    'Mehdi Beriane': 'Mehdi',
    'Nam Tiáº¿n': 'Nam',
    'Bernard Lee': 'Bernard',
    'Jaden Lee': 'Jaden',
    'Jaden Kong': 'Jaden',
    'Irene Kim': 'Irene',
    'Irene Bae': 'Irene',
    'Kevin Lee': 'Kevin',
    'Kevin Kim': 'Kevin',
    'Theo Lee': 'Theo',
    'Monica Kim': 'Monica',
    'Eugenie Nguyen': 'Eugenie',
    'Eugenie Park': 'Eugenie',
    'George Negru': 'George',
}

EXCLUDED_PATTERNS = [
    r'^Project\s', r'^DRB\s', r'^TRH\s', r'^Upgrade\s', r'^Meeting\s',
    r'^Notes\s', r'^Attachments', r'^Invited', r'^Summary', r'^Details',
    r'^Recording', r'^Transcript', r'^Gemini', r'Seminar'
]

DEFAULT_CSV_FILES = [
    'irene.recordings.csv',
    'jaden.recordings.csv',
    'shared.recordings.csv'
]

# ê¸°ìˆ  ìš©ì–´ -> ëŒ€ì¤‘ ì¹œí™”ì  í‘œí˜„ ë§¤í•‘
TECH_TO_PUBLIC = {
    # ë¸”ë¡ì²´ì¸/ì•”í˜¸í™”
    'ZKP': 'ì˜ì§€ì‹ ì¦ëª… ê¸°ìˆ ',
    'zero-knowledge proof': 'ì˜ì§€ì‹ ì¦ëª… ê¸°ìˆ ',
    'fraud proof': 'ë³´ì•ˆ ê²€ì¦ ì‹œìŠ¤í…œ',
    'fault proof': 'ì˜¤ë¥˜ ê²€ì¦ ì‹œìŠ¤í…œ',
    'rollup': 'í™•ì¥ì„± ì†”ë£¨ì…˜',
    'optimistic rollup': 'ë‚™ê´€ì  í™•ì¥ ì†”ë£¨ì…˜',
    'L1': 'ë©”ì¸ ë¸”ë¡ì²´ì¸',
    'L2': 'ë ˆì´ì–´2 í™•ì¥ ë„¤íŠ¸ì›Œí¬',
    'staking': 'í† í° ì˜ˆì¹˜',
    'slashing': 'ë¶€ì •í–‰ìœ„ í˜ë„í‹°',
    'sequencer': 'íŠ¸ëœì­ì…˜ ì²˜ë¦¬ì',
    'challenger': 'ê²€ì¦ì',
    'validator': 'ê²€ì¦ì',
    'bisection': 'ë¶„í•  ê²€ì¦',
    'dispute': 'ê²€ì¦ ë¶„ìŸ',
    'smart contract': 'ìŠ¤ë§ˆíŠ¸ ì»¨íŠ¸ë™íŠ¸',
    'contract': 'ì»¨íŠ¸ë™íŠ¸',
    'SDK': 'ê°œë°œ ë„êµ¬',
    'API': 'ì—°ë™ ì¸í„°í˜ì´ìŠ¤',
    'DRB': 'ë¶„ì‚° ëœë¤ ë¹„ì½˜',
    'PR': 'ì½”ë“œ ê¸°ì—¬',
    'PRs': 'ì½”ë“œ ê¸°ì—¬',
    'merge': 'í†µí•©',
    'branch': 'ê°œë°œ ë¸Œëœì¹˜',
    'refactoring': 'ì½”ë“œ ìµœì í™”',
    'end-to-end testing': 'í†µí•© í…ŒìŠ¤íŠ¸',
    'libP2P': 'ë„¤íŠ¸ì›Œí¬ í†µì‹  ëª¨ë“ˆ',
    'RPC': 'ì›ê²© í˜¸ì¶œ',
    'database pool': 'ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°',
    'cryptographic': 'ì•”í˜¸í™”',
    'BLS': 'ì•”í˜¸í™” ì„œëª…',
    # ì¼ë°˜ ê¸°ìˆ 
    'bug': 'ì˜¤ë¥˜',
    'debug': 'ì˜¤ë¥˜ ìˆ˜ì •',
    'deploy': 'ë°°í¬',
    'implementation': 'êµ¬í˜„',
    'integration': 'ì—°ë™',
    'scalability': 'í™•ì¥ì„±',
    'bottleneck': 'ì„±ëŠ¥ ì œì•½',
    'audit': 'ë³´ì•ˆ ê°ì‚¬',
    'auditing': 'ë³´ì•ˆ ê°ì‚¬',
}

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

def get_short_name(full_name: str) -> str:
    """í’€ë„¤ì„ì„ ì§§ì€ ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
    if full_name in NAME_MAP:
        return NAME_MAP[full_name]
    if ' ' in full_name:
        return full_name.split()[0]
    return full_name


def replace_names_in_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ ë‚´ í’€ë„¤ì„ì„ ì§§ì€ ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
    for full, short in NAME_MAP.items():
        text = text.replace(full, short)
    return text


def simplify_tech_terms(text: str) -> str:
    """ê¸°ìˆ  ìš©ì–´ë¥¼ ëŒ€ì¤‘ ì¹œí™”ì  í‘œí˜„ìœ¼ë¡œ ë³€í™˜"""
    result = text
    for tech, public in TECH_TO_PUBLIC.items():
        # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ì¹˜í™˜
        pattern = re.compile(re.escape(tech), re.IGNORECASE)
        result = pattern.sub(public, result)
    return result


def is_valid_speaker(name: str) -> bool:
    """ìœ íš¨í•œ í™”ìì¸ì§€ í™•ì¸"""
    for pattern in EXCLUDED_PATTERNS:
        if re.match(pattern, name, re.IGNORECASE):
            return False
    if name in NAME_MAP:
        return True
    words = name.split()
    if len(words) != 2:
        return False
    for w in words:
        if len(w) < 2 or len(w) > 15:
            return False
        if not w[0].isupper():
            return False
        if not re.match(r'^[A-Za-zÃ€-á»¹]+$', w):
            return False
    return True


def truncate_to_sentence(text: str, max_len: int = 250) -> str:
    """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°"""
    if len(text) <= max_len:
        return text

    truncated = text[:max_len]

    sentence_end_patterns = [
        r'ë‹¤\.\s', r'ìš”\.\s', r'ìŒ\.\s', r'ì„\.\s',
        r'ë‹¤\.$', r'ìš”\.$', r'ìŒ\.$', r'ì„\.$',
        r'\)\.\s', r'\)\.$',
        r'[a-zA-Z]\.\s', r'[a-zA-Z]\.$',
        r'\?\s', r'\?$', r'!\s', r'!$',
    ]

    last_end = -1
    for pattern in sentence_end_patterns:
        matches = list(re.finditer(pattern, truncated))
        if matches:
            pos = matches[-1].end()
            if pos > last_end:
                last_end = pos

    if last_end > 80:
        return text[:last_end].strip()

    for i in range(len(truncated) - 1, 50, -1):
        if truncated[i] == '.':
            if i > 0 and not truncated[i-1].isdigit():
                return text[:i + 1].strip()

    last_space = truncated.rfind(' ')
    if last_space > 100:
        return text[:last_space].strip() + "..."

    return truncated.strip() + "..."


def categorize_meeting(name: str, summary: str) -> str:
    """íšŒì˜ë¥¼ ëŒ€ì¤‘ ì¹œí™”ì  ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜"""
    name_lower = name.lower()
    summary_lower = summary.lower()
    combined = name_lower + ' ' + summary_lower

    if any(kw in combined for kw in ['seminar', 'ì„¸ë¯¸ë‚˜', 'research', 'paper', 'academic']):
        return 'ğŸ”¬ ì—°êµ¬ & ê¸°ìˆ  í˜ì‹ '
    elif any(kw in combined for kw in ['security', 'audit', 'fraud', 'fault', 'dispute', 'slashing']):
        return 'ğŸ›¡ï¸ ë³´ì•ˆ & ì•ˆì •ì„±'
    elif any(kw in combined for kw in ['integration', 'sdk', 'platform', 'setup', 'api']):
        return 'ğŸ”— í”Œë«í¼ & ì—°ë™'
    elif any(kw in combined for kw in ['upgrade', 'improvement', 'optimization', 'scalability']):
        return 'âš¡ ì„±ëŠ¥ & í™•ì¥ì„±'
    elif any(kw in combined for kw in ['weekly', 'progress', 'update', 'status']):
        return 'ğŸ“Š í”„ë¡œì íŠ¸ ì§„í–‰'
    elif any(kw in combined for kw in ['data', 'dashboard', 'report', 'analytics']):
        return 'ğŸ“ˆ ë°ì´í„° & ë¶„ì„'
    else:
        return 'ğŸ’¼ íŒ€ í˜‘ì—…'


def extract_business_highlights(content: str) -> dict:
    """ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì˜ í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ"""
    content = content.replace('\\r\\n', '\n').replace('\r\n', '\n')

    result = {
        'summary': '',
        'achievements': [],    # ì„±ê³¼/ë§ˆì¼ìŠ¤í†¤
        'strategic': [],       # ì „ëµì  ê²°ì •
        'partnerships': [],    # íŒŒíŠ¸ë„ˆì‹­/í˜‘ë ¥
        'next_milestones': []  # ë‹¤ìŒ ë§ˆì¼ìŠ¤í†¤
    }

    # ìš”ì•½ ì¶”ì¶œ
    summary_patterns = [
        r'ìš”ì•½\s*\n(.+?)(?=\n\nì„¸ë¶€ì •ë³´|\n\nDetails|\n\n\n)',
        r'Summary\s*\n(.+?)(?=\n\nDetails|\n\n\n)',
    ]

    for pattern in summary_patterns:
        match = re.search(pattern, content, re.DOTALL)
        if match:
            raw_summary = match.group(1).strip()
            # ì´ë¦„ ë³€í™˜ ë° ê¸°ìˆ  ìš©ì–´ ë‹¨ìˆœí™”
            result['summary'] = simplify_tech_terms(replace_names_in_text(raw_summary))
            break

    # ì„¸ë¶€ì •ë³´ì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ
    details_patterns = [
        r'ì„¸ë¶€ì •ë³´\s*\n(.+?)(?=\nì¶”ì²œí•˜ëŠ” ë‹¤ìŒ ë‹¨ê³„|\n\n\n|$)',
        r'Details\s*\n(.+?)(?=\nSuggested next steps|\n\n\n|$)',
    ]

    details_text = ''
    for pattern in details_patterns:
        match = re.search(pattern, content, re.DOTALL)
        if match:
            details_text = match.group(1).strip()
            break

    if details_text:
        bullets = re.findall(r'\* ([^\n]+(?:\n(?!\*)[^\n]+)*)', details_text)

        for bullet in bullets:
            bullet_lower = bullet.lower()
            bullet_clean = simplify_tech_terms(replace_names_in_text(bullet))
            first_line = bullet_clean.split('\n')[0]

            # ì„±ê³¼/ë§ˆì¼ìŠ¤í†¤ (ì™„ë£Œ, ë‹¬ì„±, ì¶œì‹œ ë“±)
            if any(kw in bullet_lower for kw in ['ì™„ë£Œ', 'completed', 'finished', 'achieved', 'launched',
                                                   'released', 'delivered', 'milestone', 'ë‹¬ì„±', 'ì¶œì‹œ']):
                result['achievements'].append(first_line)
            # ì „ëµì  ê²°ì •
            elif any(kw in bullet_lower for kw in ['ê²°ì •', 'decided', 'agreed', 'strategy', 'plan',
                                                    'ì „ëµ', 'approach', 'direction']):
                result['strategic'].append(first_line)
            # íŒŒíŠ¸ë„ˆì‹­/í˜‘ë ¥
            elif any(kw in bullet_lower for kw in ['partner', 'collaboration', 'integration', 'cooperation',
                                                    'í˜‘ë ¥', 'íŒŒíŠ¸ë„ˆ', 'ì—°ë™']):
                result['partnerships'].append(first_line)

    # ë‹¤ìŒ ë§ˆì¼ìŠ¤í†¤ ì¶”ì¶œ (ì•¡ì…˜ì•„ì´í…œì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ë§Œ)
    action_patterns = [
        r'ì¶”ì²œí•˜ëŠ” ë‹¤ìŒ ë‹¨ê³„\s*\n(.+?)(?=\n\n|$)',
        r'Suggested next steps\s*\n(.+?)(?=\n\n|$)',
    ]

    for pattern in action_patterns:
        match = re.search(pattern, content, re.DOTALL)
        if match:
            steps = match.group(1).strip()
            items = re.findall(r'\* (.+)', steps)
            for item in items:
                item_lower = item.lower()
                # ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ ì œì™¸, ë¹„ì¦ˆë‹ˆìŠ¤ ë§ˆì¼ìŠ¤í†¤ë§Œ í¬í•¨
                if any(kw in item_lower for kw in ['fix', 'bug', 'test', 'review pr', 'merge',
                                                    'refactor', 'debug', 'check']):
                    continue
                cleaned = simplify_tech_terms(replace_names_in_text(item))
                # ë‹´ë‹¹ì ì´ë¦„ ì œê±° (ëŒ€ì™¸ìš©ì´ë¯€ë¡œ)
                cleaned = re.sub(r'^[A-Za-zê°€-í£]+ë‹˜ì€?\s*(ì€|ëŠ”)?\s*', '', cleaned)
                if len(cleaned) > 20:  # ë„ˆë¬´ ì§§ì€ ê²ƒ ì œì™¸
                    result['next_milestones'].append(cleaned)

    return result


def parse_speakers_for_public(content: str) -> list:
    """ì°¸ì—¬ì ëª©ë¡ë§Œ ì¶”ì¶œ (ë°œí™”ì‹œê°„ ì œì™¸)"""
    speakers = set()
    content = content.replace('\\r\\n', '\n').replace('\r\n', '\n')

    transcript_markers = ['ğŸ“– Transcript', 'ğŸ“– ìŠ¤í¬ë¦½íŠ¸']
    transcript_start = -1
    for marker in transcript_markers:
        pos = content.find(marker)
        if pos != -1:
            transcript_start = pos
            break

    if transcript_start == -1:
        return []

    transcript_text = content[transcript_start:]
    speaker_pattern = r'^([A-Za-zÃ€-á»¹][A-Za-zÃ€-á»¹\s]{1,28}):\s*(.+)$'

    for line in transcript_text.split('\n'):
        line = line.strip()
        if not line:
            continue
        sp_match = re.match(speaker_pattern, line)
        if sp_match:
            speaker_name = sp_match.group(1).strip()
            if is_valid_speaker(speaker_name):
                speakers.add(get_short_name(speaker_name))

    return sorted(list(speakers))


# ============================================================================
# ë¦¬í¬íŠ¸ ìƒì„±
# ============================================================================

def load_meetings(csv_files: list, target_date: str) -> list:
    """CSV íŒŒì¼ë“¤ì—ì„œ íŠ¹ì • ë‚ ì§œì˜ íšŒì˜ ë°ì´í„° ë¡œë“œ"""
    meetings = []

    date_patterns = [
        target_date.replace('-', '/'),
        f"{target_date[:4]}ë…„ {int(target_date[5:7])}ì›” {int(target_date[8:10])}ì¼"
    ]

    for csv_file in csv_files:
        try:
            with open(csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)

                for row in reader:
                    name = row.get('name', '')
                    content = row.get('content', '')

                    if not content:
                        continue

                    if not any(dp in name for dp in date_patterns):
                        continue

                    if "summary wasn't produced" in content.lower():
                        continue

                    # íŒŒì‹±
                    highlights = extract_business_highlights(content)
                    participants = parse_speakers_for_public(content)

                    if not highlights['summary'] and not participants:
                        continue

                    # íšŒì˜ëª… ì •ë¦¬ ë° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
                    short_name = name
                    if ' â€“ ' in short_name:
                        short_name = short_name.split(' â€“ ')[0]
                    if ' - Gemini' in short_name:
                        short_name = short_name.split(' - Gemini')[0]
                    if 'KSTì— ì‹œì‘í•œ íšŒì˜' in short_name:
                        short_name = short_name.replace('ì— ì‹œì‘í•œ íšŒì˜', '')

                    # ë‚ ì§œ/ì‹œê°„ ì œê±°í•˜ì—¬ ë” ê¹”ë”í•˜ê²Œ
                    short_name = re.sub(r'\d{4}/\d{2}/\d{2}\s*\d{2}:\d{2}\s*(KST|GMT[^\s]*)?', '', short_name).strip()
                    if not short_name or short_name.isspace():
                        short_name = "íŒ€ ë¯¸íŒ…"

                    category = categorize_meeting(name, highlights['summary'])

                    meetings.append({
                        'name': short_name.strip(),
                        'category': category,
                        'participants': participants,
                        'summary': highlights['summary'],
                        'achievements': highlights['achievements'],
                        'strategic': highlights['strategic'],
                        'partnerships': highlights['partnerships'],
                        'next_milestones': highlights['next_milestones']
                    })
        except FileNotFoundError:
            print(f"âš ï¸  íŒŒì¼ ì—†ìŒ: {csv_file}")
            continue

    return meetings


def generate_public_report(meetings: list, target_date: str) -> str:
    """ëŒ€ì¤‘ìš© ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""

    year, month, day = target_date.split('-')
    weekdays = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
    weekday = weekdays[date(int(year), int(month), int(day)).weekday()]
    date_str = f"{year}ë…„ {int(month)}ì›” {int(day)}ì¼ ({weekday})"

    output = []

    # í—¤ë”
    output.append("# ğŸ“£ Daily Progress Report")
    output.append("")
    output.append(f"## ğŸ“… {date_str}")
    output.append("")
    output.append("> ì˜¤ëŠ˜ì˜ ì£¼ìš” ì§„í–‰ ìƒí™©ì„ ê³µìœ í•©ë‹ˆë‹¤.")
    output.append("")
    output.append("---")
    output.append("")

    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
    categories = defaultdict(list)
    for m in meetings:
        categories[m['category']].append(m)

    # ì˜¤ëŠ˜ì˜ í•˜ì´ë¼ì´íŠ¸ (ì „ì²´ ì„±ê³¼ ìš”ì•½)
    all_achievements = []
    all_strategic = []
    all_milestones = []
    all_participants = set()

    for m in meetings:
        all_achievements.extend(m['achievements'])
        all_strategic.extend(m['strategic'])
        all_milestones.extend(m['next_milestones'])
        all_participants.update(m['participants'])

    # í•µì‹¬ ìš”ì•½
    output.append("## ğŸ¯ ì˜¤ëŠ˜ì˜ í•µì‹¬ ìš”ì•½")
    output.append("")
    output.append(f"- **{len(meetings)}ê±´**ì˜ ì£¼ìš” ë¯¸íŒ… ì§„í–‰")
    output.append(f"- **{len(all_participants)}ëª…**ì˜ íŒ€ì› ì°¸ì—¬")
    if all_achievements:
        output.append(f"- **{len(all_achievements)}ê±´**ì˜ ì„±ê³¼ ë‹¬ì„±")
    output.append("")
    output.append("---")
    output.append("")

    # ì£¼ìš” ì„±ê³¼ (ìˆëŠ” ê²½ìš°)
    if all_achievements:
        output.append("## ğŸ† ì£¼ìš” ì„±ê³¼")
        output.append("")
        for achievement in all_achievements[:5]:
            output.append(f"- âœ… {truncate_to_sentence(achievement, 150)}")
        output.append("")
        output.append("---")
        output.append("")

    # ì „ëµì  ê²°ì • (ìˆëŠ” ê²½ìš°)
    if all_strategic:
        output.append("## ğŸ¯ ì „ëµì  ê²°ì •")
        output.append("")
        for strategic in all_strategic[:4]:
            output.append(f"- {truncate_to_sentence(strategic, 150)}")
        output.append("")
        output.append("---")
        output.append("")

    # ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸
    output.append("## ğŸ“‹ ë¶„ì•¼ë³„ ì§„í–‰ ìƒí™©")
    output.append("")

    category_order = [
        'ğŸ”¬ ì—°êµ¬ & ê¸°ìˆ  í˜ì‹ ',
        'ğŸ›¡ï¸ ë³´ì•ˆ & ì•ˆì •ì„±',
        'âš¡ ì„±ëŠ¥ & í™•ì¥ì„±',
        'ğŸ”— í”Œë«í¼ & ì—°ë™',
        'ğŸ“Š í”„ë¡œì íŠ¸ ì§„í–‰',
        'ğŸ“ˆ ë°ì´í„° & ë¶„ì„',
        'ğŸ’¼ íŒ€ í˜‘ì—…'
    ]

    for cat in category_order:
        if cat not in categories:
            continue

        output.append(f"### {cat}")
        output.append("")

        for m in categories[cat]:
            # íšŒì˜ ì œëª© (ìˆëŠ” ê²½ìš°ë§Œ)
            if m['name'] and m['name'] != "íŒ€ ë¯¸íŒ…":
                output.append(f"**{m['name']}**")
                output.append("")

            # ìš”ì•½
            if m['summary']:
                summary = truncate_to_sentence(m['summary'], 300)
                output.append(f"> {summary}")
                output.append("")

            # ì°¸ì—¬ì (ê°„ëµíˆ)
            if m['participants']:
                participants_str = ', '.join(m['participants'][:5])
                if len(m['participants']) > 5:
                    participants_str += f" ì™¸ {len(m['participants']) - 5}ëª…"
                output.append(f"*ì°¸ì—¬: {participants_str}*")
                output.append("")

        output.append("---")
        output.append("")

    # ë‹¤ìŒ ë§ˆì¼ìŠ¤í†¤
    if all_milestones:
        output.append("## ğŸš€ ë‹¤ìŒ ë‹¨ê³„")
        output.append("")
        seen = set()
        for milestone in all_milestones[:5]:
            # ì¤‘ë³µ ì œê±°
            milestone_short = milestone[:50]
            if milestone_short in seen:
                continue
            seen.add(milestone_short)
            output.append(f"- {truncate_to_sentence(milestone, 150)}")
        output.append("")
        output.append("---")
        output.append("")

    # í‘¸í„°
    output.append("")
    output.append("---")
    output.append("")
    output.append("*ë³¸ ë¦¬í¬íŠ¸ëŠ” íŒ€ì˜ ì¼ì¼ í™œë™ì„ ìš”ì•½í•œ ê²ƒì…ë‹ˆë‹¤.*")
    output.append("")
    output.append("**ë¬¸ì˜**: [team@example.com](mailto:team@example.com)")

    return '\n'.join(output)


# ============================================================================
# ë©”ì¸
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description='ëŒ€ì¤‘ìš© ë°ì¼ë¦¬ ë¦¬í¬íŠ¸ ìƒì„±ê¸°')
    parser.add_argument('--date', '-d', required=True, help='ë¶„ì„í•  ë‚ ì§œ (YYYY-MM-DD)')
    parser.add_argument('--output', '-o', help='ì¶œë ¥ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--csv', '-c', nargs='+', default=DEFAULT_CSV_FILES, help='ì…ë ¥ CSV íŒŒì¼ë“¤')

    args = parser.parse_args()

    try:
        from datetime import datetime
        datetime.strptime(args.date, '%Y-%m-%d')
    except ValueError:
        print(f"âŒ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {args.date} (YYYY-MM-DD í˜•ì‹ í•„ìš”)")
        sys.exit(1)

    print(f"ğŸ“… {args.date} ëŒ€ì¤‘ìš© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")

    meetings = load_meetings(args.csv, args.date)

    if not meetings:
        print(f"âš ï¸  {args.date}ì— í•´ë‹¹í•˜ëŠ” íšŒì˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(0)

    print(f"âœ… {len(meetings)}ê±´ì˜ íšŒì˜ ë°œê²¬")

    report = generate_public_report(meetings, args.date)

    if args.output:
        output_path = args.output
    else:
        date_compact = args.date.replace('-', '')
        output_path = f"public_report_{date_compact}.md"

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"âœ… ëŒ€ì¤‘ìš© ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {output_path}")
    print()
    print("=" * 60)
    print(report[:2500])
    if len(report) > 2500:
        print("...")
        print(f"(ì´ {len(report)} ë¬¸ì)")


if __name__ == '__main__':
    main()
